{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3cNGituvQ7WD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Autoencoders\n",
        "\n",
        "## Background\n",
        "\n",
        "The following autoencoder is built following the work outlined in Hinton's paper on reducing dimensionality of data (link below). In this paper, they offer a comparison between the use of **principal component analysis** (PCA), and algorithm that can reduce high dimensional data to low dimensional representation. \n",
        "\n",
        "In this context, high dimensional data referes to datasets with large numbers of features, or attributes. The high dimensionality can make it difficult to visualize and derive relationships between data points. PCA works by finding the directions of greatest variance and identifies attributes that are orthogonal, then transforming each data point to a relative coordinate along these directions.\n",
        "\n",
        "In their paper, Hinton describes a new algorithm, based on deep neural networks, to form a nonlinear generalization of PCA in a two-step process. First, transofrm high-dimensional data into a low-dimensional code, using a sequence of hidden layers, and second, to recover the original data from this code.\n",
        "\n",
        "\n",
        "\n",
        "The network works by assigning a probability to every possible image using an energy function.\n",
        "\n",
        "They apply a layer-by-layer learning model.\n",
        "\n",
        "---\n",
        "1.  ** G. E. Hinton and R. R. Salakhutdinov** [Reducing the dimensionality of data with Neural Networks](https://www.cs.toronto.edu/~hinton/science.pdf)\n",
        "2.   **F. Chollet** [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0AXx2DNk7WXv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using keras, lets build a model of Hinton's neural network for dimensionality reduction"
      ]
    },
    {
      "metadata": {
        "id": "e6DhTIcnBBqM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Hypothesis\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4KOcxaPBBFjB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Details of Experiment\n"
      ]
    },
    {
      "metadata": {
        "id": "BR9nMAaLRytf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "Load data from datasets:\n",
        "\n",
        "\n",
        "*   **MNIST**: database of handwritten digist, contains 60,000 28 x 28 image examples, and 10,000 test images\n",
        "*   **CIFAR-10**: contains 60,000 32 x 32 colour images in 1- classess, with 6,000 images per class. There are 50,000 training images and 10,000 test images\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zOw4rwNd7x_j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ea5e9b8-f333-4366-ff42-b1795581153a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521654164541,
          "user_tz": 240,
          "elapsed": 6813,
          "user": {
            "displayName": "Shahab Akmal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111070170842842490755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import keras modules for creating layers and training model\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist, cifar10\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.callbacks import Callback\n",
        "from sklearn import decomposition, discriminant_analysis\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "po3wlBCpSpsk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST Dataset\n",
        "\n",
        "Building the simplest possible autoencoder based on Hinton's model but using connected neural layers for both encoder and decoder\n"
      ]
    },
    {
      "metadata": {
        "id": "DzN6Qt-CAIYk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Shallow Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "LSxJyU6y8m1B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class LossHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.loss = []\n",
        "        self.val_loss = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.val_loss.append(logs.get('val_loss'))\n",
        "        self.val_acc.append(logs.get('val_acc'))\n",
        "        self.loss.append(logs.get('loss'))\n",
        "        self.acc.append(logs.get('acc'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7J9qwGRWK00D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "416e7455-0497-41cf-9c33-8fd72834386e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521654171782,
          "user_tz": 240,
          "elapsed": 1263,
          "user": {
            "displayName": "Shahab Akmal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111070170842842490755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# splitting training set\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# normalize data between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lHLZ7ZJA9i4W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# place holder for data \n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# shallow autoencoder\n",
        "encoded = Dense(50, activation='relu')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "shallow_encoder = Model(input_img, encoded)\n",
        "\n",
        "shallow_autoencoder = Model(input_img, decoded)\n",
        "shallow_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fy6VOdHz9fDY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 52
            },
            {
              "item_id": 98
            },
            {
              "item_id": 148
            },
            {
              "item_id": 196
            },
            {
              "item_id": 246
            },
            {
              "item_id": 297
            },
            {
              "item_id": 346
            },
            {
              "item_id": 394
            },
            {
              "item_id": 444
            },
            {
              "item_id": 495
            },
            {
              "item_id": 546
            },
            {
              "item_id": 597
            },
            {
              "item_id": 648
            },
            {
              "item_id": 699
            },
            {
              "item_id": 750
            },
            {
              "item_id": 757
            },
            {
              "item_id": 758
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 2621
        },
        "collapsed": true,
        "outputId": "e683579c-8343-40fe-bf7f-8c950e7492e3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521654379336,
          "user_tz": 240,
          "elapsed": 198832,
          "user": {
            "displayName": "Shahab Akmal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111070170842842490755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "shallow_history = LossHistory()        \n",
        "# train shallow autoencoder model\n",
        "shallow_autoencoder.fit(x_train, x_train,\n",
        "                epochs=75,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                callbacks=[shallow_history],\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/75\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.3036 - acc: 0.7794 - val_loss: 0.2470 - val_acc: 0.7988\n",
            "Epoch 2/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.2238 - acc: 0.7993 - val_loss: 0.2024 - val_acc: 0.7985\n",
            "Epoch 3/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1921 - acc: 0.8011 - val_loss: 0.1807 - val_acc: 0.8010\n",
            "Epoch 4/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1752 - acc: 0.8033 - val_loss: 0.1672 - val_acc: 0.8038\n",
            "Epoch 5/75\n",
            "56064/60000 [===========================>..] - ETA: 0s - loss: 0.1636 - acc: 0.8052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1633 - acc: 0.8052 - val_loss: 0.1566 - val_acc: 0.8055\n",
            "Epoch 6/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1536 - acc: 0.8069 - val_loss: 0.1478 - val_acc: 0.8069\n",
            "Epoch 7/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.1457 - acc: 0.8081 - val_loss: 0.1407 - val_acc: 0.8082\n",
            "Epoch 8/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1391 - acc: 0.8091 - val_loss: 0.1345 - val_acc: 0.8088\n",
            "Epoch 9/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1335 - acc: 0.8099 - val_loss: 0.1293 - val_acc: 0.8094\n",
            "Epoch 10/75\n",
            "26752/60000 [============>.................] - ETA: 1s - loss: 0.1299 - acc: 0.8104"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.1285 - acc: 0.8106 - val_loss: 0.1245 - val_acc: 0.8102\n",
            "Epoch 11/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.1239 - acc: 0.8112 - val_loss: 0.1201 - val_acc: 0.8107\n",
            "Epoch 12/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.1198 - acc: 0.8118 - val_loss: 0.1162 - val_acc: 0.8113\n",
            "Epoch 13/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1160 - acc: 0.8123 - val_loss: 0.1126 - val_acc: 0.8116\n",
            "Epoch 14/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1127 - acc: 0.8126 - val_loss: 0.1096 - val_acc: 0.8120\n",
            "Epoch 15/75\n",
            "22016/60000 [==========>...................] - ETA: 1s - loss: 0.1107 - acc: 0.8127"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1099 - acc: 0.8130 - val_loss: 0.1070 - val_acc: 0.8123\n",
            "Epoch 16/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1074 - acc: 0.8132 - val_loss: 0.1046 - val_acc: 0.8124\n",
            "Epoch 17/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1052 - acc: 0.8134 - val_loss: 0.1026 - val_acc: 0.8126\n",
            "Epoch 18/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1033 - acc: 0.8136 - val_loss: 0.1009 - val_acc: 0.8128\n",
            "Epoch 19/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.1016 - acc: 0.8137 - val_loss: 0.0993 - val_acc: 0.8129\n",
            "Epoch 20/75\n",
            "19968/60000 [========>.....................] - ETA: 1s - loss: 0.1004 - acc: 0.8136"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.1001 - acc: 0.8138 - val_loss: 0.0979 - val_acc: 0.8130\n",
            "Epoch 21/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0988 - acc: 0.8139 - val_loss: 0.0967 - val_acc: 0.8131\n",
            "Epoch 22/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0976 - acc: 0.8140 - val_loss: 0.0955 - val_acc: 0.8131\n",
            "Epoch 23/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0965 - acc: 0.8141 - val_loss: 0.0945 - val_acc: 0.8132\n",
            "Epoch 24/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0955 - acc: 0.8142 - val_loss: 0.0936 - val_acc: 0.8133\n",
            "Epoch 25/75\n",
            "21888/60000 [=========>....................] - ETA: 1s - loss: 0.0949 - acc: 0.8141"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0946 - acc: 0.8142 - val_loss: 0.0928 - val_acc: 0.8134\n",
            "Epoch 26/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0938 - acc: 0.8143 - val_loss: 0.0920 - val_acc: 0.8134\n",
            "Epoch 27/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0930 - acc: 0.8143 - val_loss: 0.0913 - val_acc: 0.8134\n",
            "Epoch 28/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0923 - acc: 0.8144 - val_loss: 0.0907 - val_acc: 0.8135\n",
            "Epoch 29/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0917 - acc: 0.8144 - val_loss: 0.0901 - val_acc: 0.8135\n",
            "Epoch 30/75\n",
            "23680/60000 [==========>...................] - ETA: 1s - loss: 0.0914 - acc: 0.8142"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0911 - acc: 0.8144 - val_loss: 0.0895 - val_acc: 0.8135\n",
            "Epoch 31/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0906 - acc: 0.8145 - val_loss: 0.0890 - val_acc: 0.8136\n",
            "Epoch 32/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0901 - acc: 0.8145 - val_loss: 0.0885 - val_acc: 0.8136\n",
            "Epoch 33/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0896 - acc: 0.8145 - val_loss: 0.0881 - val_acc: 0.8136\n",
            "Epoch 34/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0891 - acc: 0.8146 - val_loss: 0.0876 - val_acc: 0.8137\n",
            "Epoch 35/75\n",
            "19456/60000 [========>.....................] - ETA: 1s - loss: 0.0889 - acc: 0.8142"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0887 - acc: 0.8146 - val_loss: 0.0873 - val_acc: 0.8137\n",
            "Epoch 36/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0883 - acc: 0.8146 - val_loss: 0.0869 - val_acc: 0.8137\n",
            "Epoch 37/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0879 - acc: 0.8146 - val_loss: 0.0865 - val_acc: 0.8137\n",
            "Epoch 38/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0876 - acc: 0.8146 - val_loss: 0.0862 - val_acc: 0.8137\n",
            "Epoch 39/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0873 - acc: 0.8147 - val_loss: 0.0859 - val_acc: 0.8138\n",
            "Epoch 40/75\n",
            "20864/60000 [=========>....................] - ETA: 1s - loss: 0.0871 - acc: 0.8144"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0869 - acc: 0.8147 - val_loss: 0.0856 - val_acc: 0.8138\n",
            "Epoch 41/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0866 - acc: 0.8147 - val_loss: 0.0853 - val_acc: 0.8138\n",
            "Epoch 42/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0864 - acc: 0.8147 - val_loss: 0.0851 - val_acc: 0.8138\n",
            "Epoch 43/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0861 - acc: 0.8147 - val_loss: 0.0848 - val_acc: 0.8138\n",
            "Epoch 44/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0858 - acc: 0.8147 - val_loss: 0.0846 - val_acc: 0.8138\n",
            "Epoch 45/75\n",
            "20608/60000 [=========>....................] - ETA: 1s - loss: 0.0855 - acc: 0.8149"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0856 - acc: 0.8148 - val_loss: 0.0843 - val_acc: 0.8138\n",
            "Epoch 46/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0854 - acc: 0.8148 - val_loss: 0.0841 - val_acc: 0.8138\n",
            "Epoch 47/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0851 - acc: 0.8148 - val_loss: 0.0839 - val_acc: 0.8138\n",
            "Epoch 48/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0849 - acc: 0.8148 - val_loss: 0.0837 - val_acc: 0.8139\n",
            "Epoch 49/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0847 - acc: 0.8148 - val_loss: 0.0835 - val_acc: 0.8139\n",
            "Epoch 50/75\n",
            "20480/60000 [=========>....................] - ETA: 1s - loss: 0.0849 - acc: 0.8145"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0845 - acc: 0.8148 - val_loss: 0.0833 - val_acc: 0.8139\n",
            "Epoch 51/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0843 - acc: 0.8148 - val_loss: 0.0832 - val_acc: 0.8139\n",
            "Epoch 52/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0842 - acc: 0.8148 - val_loss: 0.0830 - val_acc: 0.8139\n",
            "Epoch 53/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0840 - acc: 0.8148 - val_loss: 0.0828 - val_acc: 0.8139\n",
            "Epoch 54/75\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0838 - acc: 0.8148 - val_loss: 0.0827 - val_acc: 0.8139\n",
            "Epoch 55/75\n",
            "19456/60000 [========>.....................] - ETA: 1s - loss: 0.0838 - acc: 0.8148"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0837 - acc: 0.8149 - val_loss: 0.0825 - val_acc: 0.8139\n",
            "Epoch 56/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0835 - acc: 0.8149 - val_loss: 0.0824 - val_acc: 0.8139\n",
            "Epoch 57/75\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.0834 - acc: 0.8149 - val_loss: 0.0823 - val_acc: 0.8139\n",
            "Epoch 58/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0833 - acc: 0.8149 - val_loss: 0.0821 - val_acc: 0.8139\n",
            "Epoch 59/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0831 - acc: 0.8149 - val_loss: 0.0820 - val_acc: 0.8139\n",
            "Epoch 60/75\n",
            "20224/60000 [=========>....................] - ETA: 1s - loss: 0.0828 - acc: 0.8155"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0830 - acc: 0.8149 - val_loss: 0.0819 - val_acc: 0.8140\n",
            "Epoch 61/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0829 - acc: 0.8149 - val_loss: 0.0818 - val_acc: 0.8140\n",
            "Epoch 62/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0828 - acc: 0.8149 - val_loss: 0.0817 - val_acc: 0.8140\n",
            "Epoch 63/75\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0827 - acc: 0.8149 - val_loss: 0.0816 - val_acc: 0.8140\n",
            "Epoch 64/75\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0826 - acc: 0.8149 - val_loss: 0.0815 - val_acc: 0.8140\n",
            "Epoch 65/75\n",
            "17792/60000 [=======>......................] - ETA: 1s - loss: 0.0823 - acc: 0.8150"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0825 - acc: 0.8149 - val_loss: 0.0814 - val_acc: 0.8140\n",
            "Epoch 66/75\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0824 - acc: 0.8149 - val_loss: 0.0813 - val_acc: 0.8140\n",
            "Epoch 67/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0823 - acc: 0.8149 - val_loss: 0.0812 - val_acc: 0.8140\n",
            "Epoch 68/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0822 - acc: 0.8149 - val_loss: 0.0811 - val_acc: 0.8140\n",
            "Epoch 69/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0821 - acc: 0.8149 - val_loss: 0.0810 - val_acc: 0.8140\n",
            "Epoch 70/75\n",
            "16768/60000 [=======>......................] - ETA: 1s - loss: 0.0820 - acc: 0.8152"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.0820 - acc: 0.8149 - val_loss: 0.0810 - val_acc: 0.8140\n",
            "Epoch 71/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0819 - acc: 0.8149 - val_loss: 0.0809 - val_acc: 0.8140\n",
            "Epoch 72/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0819 - acc: 0.8149 - val_loss: 0.0808 - val_acc: 0.8140\n",
            "Epoch 73/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0818 - acc: 0.8149 - val_loss: 0.0808 - val_acc: 0.8140\n",
            "Epoch 74/75\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0817 - acc: 0.8149 - val_loss: 0.0807 - val_acc: 0.8140\n",
            "Epoch 75/75\n",
            "19072/60000 [========>.....................] - ETA: 1s - loss: 0.0816 - acc: 0.8152"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0817 - acc: 0.8150 - val_loss: 0.0807 - val_acc: 0.8140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9e8a7416a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "hUG79CPKAK7J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Deep Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "wnM5SIkpFb_K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# deep autoencoder\n",
        "\n",
        "# encoder\n",
        "encoded = Dense(1000, activation='relu')(input_img)\n",
        "encoded = Dense(500, activation='relu')(encoded)\n",
        "encoded = Dense(250, activation='relu')(encoded)\n",
        "encoded = Dense(125, activation='relu')(encoded)\n",
        "encoded = Dense(30, activation='relu')(encoded)\n",
        "\n",
        "\n",
        "# code layer\n",
        "encoded = Dense(2, activation='relu')(encoded)\n",
        "\n",
        "# decoder\n",
        "decoded = Dense(30, activation='relu')(encoded)\n",
        "decoded = Dense(125, activation='relu')(decoded)\n",
        "decoded = Dense(250, activation='relu')(decoded)\n",
        "decoded = Dense(500, activation='relu')(decoded)\n",
        "decoded = Dense(1000, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "# \n",
        "deep_encoder = Model(input_img, encoded)\n",
        "deep_autoencoder = Model(input_img, decoded)\n",
        "deep_history = LossHistory()\n",
        "\n",
        "# \n",
        "deep_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6KkgMFi79Z3B",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# train deep autoencoder model\n",
        "deep_autoencoder.fit(x_train, x_train,\n",
        "                epochs=75,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                callbacks=[deep_history],\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AoZk_j94ntwA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "# encode training/test images\n",
        "shallow_encoded_imgs = shallow_encoder.predict(x_test)\n",
        "shallow_decoded_imgs = shallow_autoencoder.predict(x_test)\n",
        "deep_encoded_imgs = deep_encoder.predict(x_test)\n",
        "deep_decoded_imgs = deep_autoencoder.predict(x_test)\n",
        "\n",
        "# PCA analysis for comparison\n",
        "pca = decomposition.PCA(n_components=2)\n",
        "pca.fit(x_test)\n",
        "pca_x = pca.transform(x_test)\n",
        "x_pca = pca.inverse_transform(pca_x)\n",
        "\n",
        "# LDA analysis for comparision\n",
        "lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=2)\n",
        "x_lda = lda.fit_transform(x_test, y_test)\n",
        "lda_x = lda.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sCSV7NAofbR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# plot comparison between pca and autoencoder\n",
        "\n",
        "plt.figure(0)\n",
        "plt.scatter(shallow_encoded_imgs[:, 0], shallow_encoded_imgs[:, 1], c=y_test, cmap='jet')\n",
        "plt.title('Shallow Autoencoder')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OVGPqecr87hI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.scatter(deep_encoded_imgs[:, 0], deep_encoded_imgs[:, 1], c=y_test, cmap='jet')\n",
        "plt.title('Deep Autoencoder')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J0oNXqVH88va",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(3)\n",
        "plt.scatter(pca_x[:, 0], pca_x[:, 1], c=y_test, cmap='jet')\n",
        "plt.title('PCA')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGTE2oWq896K",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(4)\n",
        "plt.scatter(x_lda[:, 0], x_lda[:, 1], c=y_test, cmap='jet')\n",
        "plt.title('LDA')\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DFFdMtQxe5a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# plot figures\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  \n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display autoencoder reconstruction\n",
        "    ax = plt.subplot(3, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # display pca reconstruction\n",
        "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
        "    plt.imshow(x_pca[i, :].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhTyS21Nwjx6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Deep Denoising\n"
      ]
    },
    {
      "metadata": {
        "id": "Qo5wX6II9sdo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Noisy\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, \n",
        "                                                          scale=1.0, \n",
        "                                                          size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0,\n",
        "                                                        scale=1.0,\n",
        "                                                        size=x_test.shape)\n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGTglyxM9vv6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "shallow_history_noisy = LossHistory()    \n",
        "\n",
        "# train shallow autoencoder model\n",
        "shallow_autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=75,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                callbacks=[shallow_history_noisy],\n",
        "                validation_data=(x_test_noisy, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "puN1blpiwocG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "deep_autoencoder_noisy = Model(input_img, decoded)\n",
        "deep_autoencoder_noisy.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "deep_noisy_history = LossHistory()\n",
        "\n",
        "# retrain model on noisy images\n",
        "deep_autoencoder_noisy.fit(x_train_noisy, x_train,\n",
        "                epochs=75,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                callbacks=[deep_noisy_history],\n",
        "                validation_data=(x_test_noisy, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJWnfFDHyWQA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "decoded_imgs = deep_autoencoder_noisy.predict(x_test_noisy)\n",
        "\n",
        "# plot noisy images\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "    # noisy image\n",
        "    ax = plt.subplot(2, n, 1 + i)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # reconstruction\n",
        "    ax = plt.subplot(2, n, 1 + i +n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxmjB3cZFcvj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolutional Neural Networks\n",
        "\n",
        "Building an Autoencoder using CNN's"
      ]
    },
    {
      "metadata": {
        "id": "j6woHkZQTdMY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define input size\n",
        "input_img = Input(shape=(28, 28, 1))  # as required by CNN\n",
        "\n",
        "x = input_img  # initial state\n",
        "kernel = 3\n",
        "filters = [32, 32]\n",
        "\n",
        "# encode image using Conv2D\n",
        "for nfilter in filters:\n",
        "  x = Conv2D(nfilter, kernel_size=kernel, activation='relu', padding='same')(x)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "\n",
        "# reconstructions\n",
        "for nfilter in reversed(filters):\n",
        "  x = Conv2D(nfilter, kernel_size=kernel, activation='relu', padding='same')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "                     \n",
        "decoded = Conv2D(1, kernel_size=kernel, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), 28, 28, 1))\n",
        "x_test = x_test.reshape((len(x_test), 28, 28, 1))\n",
        "\n",
        "conv_autoencoder = Model(input_img, decoded)\n",
        "\n",
        "conv_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "conv_history = LossHistory()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XvxF1x0WpzV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv_autoencoder.fit(x_train, x_train, \n",
        "                     epochs=75, \n",
        "                     batch_size=128, \n",
        "                     shuffle=True,\n",
        "                     callbacks=[conv_history],\n",
        "                     validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rsn8XZuDpKT7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "decoded_imgs = deep_autoencoder.predict(x_test)\n",
        "\n",
        "# plot noisy images\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(n):\n",
        "    # noisy image\n",
        "    ax = plt.subplot(2, n, 1 + i)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # reconstruction\n",
        "    ax = plt.subplot(2, n, 1 + i +n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8F7On1D5XJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Convolution Denoising\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "M5ucOE6e5BXl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv_autoencoder_noisy = Model(input_img, decoded)\n",
        "\n",
        "conv_autoencoder_noisy.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "conv_history_noisy = LossHistory()\n",
        "\n",
        "conv_autoencoder_noisy.fit(x_train_noisy, x_train, \n",
        "                epochs=75, \n",
        "                batch_size=128, \n",
        "                shuffle=True,\n",
        "                callbacks=[conv_history_noisy],\n",
        "                validation_data=(x_test_noisy, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ysYO37c6f_m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# plot noisy images\n",
        "decoded_imgs = conv_autoencoder_noisy.predict(x_test_noisy)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "plt.title('Denoising')\n",
        "for i in range(n):\n",
        "    # noisy image\n",
        "    ax = plt.subplot(2, n, 1 + i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # reconstruction\n",
        "    ax = plt.subplot(2, n, 1 + i +n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ohvsXUMdQLOI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## CIFRAR 10 Dataset"
      ]
    },
    {
      "metadata": {
        "id": "WnsYOUQJQ1lg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 136
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d599e659-3573-428c-d8ca-a1b4f282ae8d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521660059098,
          "user_tz": 240,
          "elapsed": 37903,
          "user": {
            "displayName": "Shahab Akmal",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111070170842842490755"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "train_size, height, width, color_layers = x_train.shape\n",
        "\n",
        "x_train = x_train.astype('float32') / np.max(x_train) \n",
        "x_test = x_test.astype('float32') / np.max(x_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 35s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8J2xLGjxQXDM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# define input size\n",
        "input_img = Input(shape=(height, width, color_layers))  # as required by CNN\n",
        "\n",
        "x = input_img  # initial state\n",
        "kernel = 3\n",
        "filters = [64, 32, 16, 8]\n",
        "\n",
        "# encode image using Conv2D\n",
        "for nfilter in filters:\n",
        "    x = Conv2D(nfilter, kernel_size=kernel, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "\n",
        "encoded = x\n",
        "\n",
        "# reconstructions\n",
        "for nfilter in reversed(filters):\n",
        "    x = Conv2D(nfilter, kernel_size=kernel, activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "                     \n",
        "decoded = Conv2D(3, kernel_size=kernel, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "\n",
        "conv_autoencoder_cifar = Model(input_img, decoded)\n",
        "conv_autoencoder_cifar.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "conv_cifar_history = LossHistory()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JDJVenFRL62",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 142
            },
            {
              "item_id": 274
            },
            {
              "item_id": 421
            },
            {
              "item_id": 580
            },
            {
              "item_id": 739
            },
            {
              "item_id": 893
            },
            {
              "item_id": 1044
            },
            {
              "item_id": 1200
            },
            {
              "item_id": 1356
            },
            {
              "item_id": 1515
            },
            {
              "item_id": 1668
            },
            {
              "item_id": 1823
            },
            {
              "item_id": 1977
            },
            {
              "item_id": 2123
            },
            {
              "item_id": 2272
            },
            {
              "item_id": 2426
            },
            {
              "item_id": 2553
            },
            {
              "item_id": 2647
            },
            {
              "item_id": 2753
            },
            {
              "item_id": 2892
            },
            {
              "item_id": 3037
            },
            {
              "item_id": 3182
            },
            {
              "item_id": 3330
            },
            {
              "item_id": 3480
            },
            {
              "item_id": 3629
            },
            {
              "item_id": 3702
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1788
        },
        "outputId": "6069d848-d8a1-4a97-cdae-bd4c284e21ca"
      },
      "cell_type": "code",
      "source": [
        "conv_autoencoder_cifar.fit(x_train, x_train,\n",
        "                     epochs=75,\n",
        "                     batch_size=128,\n",
        "                     shuffle=True,\n",
        "                     callbacks=[conv_cifar_history],\n",
        "                     validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/75\n",
            "50000/50000 [==============================] - 22s 446us/step - loss: 0.6611 - val_loss: 0.6393\n",
            "Epoch 2/75\n",
            "38912/50000 [======================>.......] - ETA: 4s - loss: 0.6335"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 417us/step - loss: 0.6318 - val_loss: 0.6227\n",
            "Epoch 3/75\n",
            "50000/50000 [==============================] - 21s 416us/step - loss: 0.6248 - val_loss: 0.6218\n",
            "Epoch 4/75\n",
            "21632/50000 [===========>..................] - ETA: 11s - loss: 0.6217"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 416us/step - loss: 0.6210 - val_loss: 0.6193\n",
            "Epoch 5/75\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 0.6177 - val_loss: 0.6120\n",
            "Epoch 6/75\n",
            "13952/50000 [=======>......................] - ETA: 14s - loss: 0.6159"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 419us/step - loss: 0.6147 - val_loss: 0.6142\n",
            "Epoch 7/75\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 0.6120 - val_loss: 0.6228\n",
            "Epoch 8/75\n",
            "13824/50000 [=======>......................] - ETA: 14s - loss: 0.6112"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 416us/step - loss: 0.6099 - val_loss: 0.6114\n",
            "Epoch 9/75\n",
            "50000/50000 [==============================] - 21s 416us/step - loss: 0.6080 - val_loss: 0.6043\n",
            "Epoch 10/75\n",
            "14976/50000 [=======>......................] - ETA: 13s - loss: 0.6078"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 417us/step - loss: 0.6069 - val_loss: 0.6131\n",
            "Epoch 11/75\n",
            "50000/50000 [==============================] - 21s 418us/step - loss: 0.6058 - val_loss: 0.6067\n",
            "Epoch 12/75\n",
            "13056/50000 [======>.......................] - ETA: 14s - loss: 0.6049"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 420us/step - loss: 0.6046 - val_loss: 0.6046\n",
            "Epoch 13/75\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.6027 - val_loss: 0.6027\n",
            "Epoch 14/75\n",
            "10880/50000 [=====>........................] - ETA: 15s - loss: 0.6020"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.6015 - val_loss: 0.5988\n",
            "Epoch 15/75\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.6007 - val_loss: 0.6015\n",
            "Epoch 16/75\n",
            " 9984/50000 [====>.........................] - ETA: 15s - loss: 0.6003"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.5998 - val_loss: 0.5998\n",
            "Epoch 17/75\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.5990 - val_loss: 0.5987\n",
            "Epoch 18/75\n",
            " 9600/50000 [====>.........................] - ETA: 16s - loss: 0.5980"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.5980 - val_loss: 0.5964\n",
            "Epoch 19/75\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.5973 - val_loss: 0.5994\n",
            "Epoch 20/75\n",
            "11136/50000 [=====>........................] - ETA: 15s - loss: 0.5978"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 420us/step - loss: 0.5971 - val_loss: 0.5997\n",
            "Epoch 21/75\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.5968 - val_loss: 0.5969\n",
            "Epoch 22/75\n",
            "10624/50000 [=====>........................] - ETA: 15s - loss: 0.5964"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.5964 - val_loss: 0.5975\n",
            "Epoch 23/75\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.5959 - val_loss: 0.5965\n",
            "Epoch 24/75\n",
            "10112/50000 [=====>........................] - ETA: 15s - loss: 0.5954"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.5955 - val_loss: 0.5952\n",
            "Epoch 25/75\n",
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.5952 - val_loss: 0.5962\n",
            "Epoch 26/75\n",
            "11136/50000 [=====>........................] - ETA: 15s - loss: 0.5956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.5951 - val_loss: 0.5946\n",
            "Epoch 27/75\n",
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.5947 - val_loss: 0.5964\n",
            "Epoch 28/75\n",
            " 9344/50000 [====>.........................] - ETA: 16s - loss: 0.5953"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.5942 - val_loss: 0.5964\n",
            "Epoch 29/75\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.5940 - val_loss: 0.5925\n",
            "Epoch 30/75\n",
            " 8832/50000 [====>.........................] - ETA: 16s - loss: 0.5937"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.5935 - val_loss: 0.5996\n",
            "Epoch 31/75\n",
            "50000/50000 [==============================] - 21s 420us/step - loss: 0.5935 - val_loss: 0.5937\n",
            "Epoch 32/75\n",
            "11264/50000 [=====>........................] - ETA: 15s - loss: 0.5937"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 420us/step - loss: 0.5931 - val_loss: 0.5934\n",
            "Epoch 33/75\n",
            "50000/50000 [==============================] - 21s 420us/step - loss: 0.5926 - val_loss: 0.5948\n",
            "Epoch 34/75\n",
            "10368/50000 [=====>........................] - ETA: 16s - loss: 0.5924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.5925 - val_loss: 0.5943\n",
            "Epoch 35/75\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.5924 - val_loss: 0.5927\n",
            "Epoch 36/75\n",
            " 8960/50000 [====>.........................] - ETA: 16s - loss: 0.5933"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 421us/step - loss: 0.5920 - val_loss: 0.5934\n",
            "Epoch 37/75\n",
            "50000/50000 [==============================] - 21s 427us/step - loss: 0.5920 - val_loss: 0.5918\n",
            "Epoch 38/75\n",
            " 7424/50000 [===>..........................] - ETA: 17s - loss: 0.5913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 425us/step - loss: 0.5916 - val_loss: 0.5913\n",
            "Epoch 39/75\n",
            "50000/50000 [==============================] - 21s 425us/step - loss: 0.5917 - val_loss: 0.5912\n",
            "Epoch 40/75\n",
            " 8448/50000 [====>.........................] - ETA: 16s - loss: 0.5924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 425us/step - loss: 0.5913 - val_loss: 0.5965\n",
            "Epoch 41/75\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.5913 - val_loss: 0.5912\n",
            "Epoch 42/75\n",
            " 8576/50000 [====>.........................] - ETA: 16s - loss: 0.5909"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.5911 - val_loss: 0.5944\n",
            "Epoch 43/75\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.5911 - val_loss: 0.5919\n",
            "Epoch 44/75\n",
            " 8320/50000 [===>..........................] - ETA: 16s - loss: 0.5926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 422us/step - loss: 0.5909 - val_loss: 0.5920\n",
            "Epoch 45/75\n",
            "50000/50000 [==============================] - 21s 424us/step - loss: 0.5908 - val_loss: 0.5929\n",
            "Epoch 46/75\n",
            " 8192/50000 [===>..........................] - ETA: 16s - loss: 0.5910"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.5906 - val_loss: 0.5910\n",
            "Epoch 47/75\n",
            "50000/50000 [==============================] - 21s 423us/step - loss: 0.5905 - val_loss: 0.5916\n",
            "Epoch 48/75\n",
            " 9216/50000 [====>.........................] - ETA: 16s - loss: 0.5903"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 420us/step - loss: 0.5904 - val_loss: 0.5905\n",
            "Epoch 49/75\n",
            "50000/50000 [==============================] - 21s 419us/step - loss: 0.5904 - val_loss: 0.5894\n",
            "Epoch 50/75\n",
            "10752/50000 [=====>........................] - ETA: 15s - loss: 0.5901"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 21s 419us/step - loss: 0.5903 - val_loss: 0.5911\n",
            "Epoch 51/75\n",
            "11264/50000 [=====>........................] - ETA: 15s - loss: 0.5913"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8_ENxS3FCe4E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# plot noisy images\n",
        "decoded_imgs = conv_autoencoder_cifar.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "plt.title('Denoising')\n",
        "for i in range(n):\n",
        "    # noisy image\n",
        "    ax = plt.subplot(2, n, 1 + i)\n",
        "    plt.imshow(x_test[i].reshape(32, 32))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # reconstruction\n",
        "    ax = plt.subplot(2, n, 1 + i +n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(32, 32))\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F7cVBJsBe1e8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Shallow-Autoencoder"
      ]
    },
    {
      "metadata": {
        "id": "QqxNwA8Ge4z8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(shallow_history.acc, 'r')\n",
        "plt.plot(shallow_history.val_acc, 'g')\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(shallow_history.loss, 'r')\n",
        "plt.plot(shallow_history.val_loss, 'g')\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69SL1zopgDfK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "Deep-Autoencoder"
      ]
    },
    {
      "metadata": {
        "id": "lDgO31nXgR48",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(deep_history.acc, 'r')\n",
        "plt.plot(deep_history.val_acc, 'g')\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(deep_history.loss, 'r')\n",
        "plt.plot(deep_history.val_loss, 'g')\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUY1DvOegGFl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Convolution Autoencoder --> MNIST"
      ]
    },
    {
      "metadata": {
        "id": "rio9-oy3gZ8z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(conv_history.acc, 'r')\n",
        "plt.plot(conv_history.val_acc, 'g')\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(conv_history.loss, 'r')\n",
        "plt.plot(conv_history.val_loss, 'g')\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train', 'validation'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_gotiTwIBQ8z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Next Actions\n",
        "\n",
        "\n",
        "\n",
        "1.   Variational Autoencoder (VAE)\n",
        "2.   Capsul Networks\n",
        "\n"
      ]
    }
  ]
}